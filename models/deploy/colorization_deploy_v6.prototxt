name: "Colorization_v5_grayscale"

#--------------------Data Layers----------------#
layer {
  name: "data_l"
  type: "Input"
  top: "data_l"
  input_param {
    shape { dim: 1 dim: 1 dim: 176 dim: 176 }
  }
}

layer {
  name: "ref_lab"
  type: "Input"
  top: "ref_lab"
  input_param {
    shape { dim: 1 dim: 3 dim: 176 dim: 176 }
  }
}

# *****************
# ***** conv1 *****
# *****************
layer {
  name: "bw_conv1_1"
  type: "Convolution"
  bottom: "data_l"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2norm"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv2 *****
# *****************
layer {
  name: "conv2_1"
  type: "Convolution"
  # bottom: "conv1_2"
  bottom: "conv1_2norm"
  # bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2norm"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv3 *****
# *****************
layer {
  name: "conv3_1"
  type: "Convolution"
  # bottom: "conv2_2"
  bottom: "conv2_2norm"
  # bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_3norm"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}



#--------------------Reference Branch------------------#

# *****************
# ***** conv1 *****
# *****************
layer {
  name: "ref_bw_conv1_1"
  type: "Convolution"
  bottom: "ref_lab"
  top: "ref_conv1_1"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
  weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "ref_relu1_1"
  type: "ReLU"
  bottom: "ref_conv1_1"
  top: "ref_conv1_1"
}
layer {
  name: "ref_conv1_2"
  type: "Convolution"
  bottom: "ref_conv1_1"
  top: "ref_conv1_2"

  convolution_param {
      weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ref_relu1_2"
  type: "ReLU"
  bottom: "ref_conv1_2"
  top: "ref_conv1_2"
}
layer {
  name: "ref_conv1_2norm"
  type: "BatchNorm"
  bottom: "ref_conv1_2"
  top: "ref_conv1_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv2 *****
# *****************
layer {
  name: "ref_conv2_1"
  type: "Convolution"
  # bottom: "ref_conv1_2"
  bottom: "ref_conv1_2norm"
  # bottom: "ref_pool1"
  top: "ref_conv2_1"

  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "ref_relu2_1"
  type: "ReLU"
  bottom: "ref_conv2_1"
  top: "ref_conv2_1"
}
layer {
  name: "ref_conv2_2"
  type: "Convolution"
  bottom: "ref_conv2_1"
  top: "ref_conv2_2"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ref_relu2_2"
  type: "ReLU"
  bottom: "ref_conv2_2"
  top: "ref_conv2_2"
}
layer {
  name: "ref_conv2_2norm"
  type: "BatchNorm"
  bottom: "ref_conv2_2"
  top: "ref_conv2_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv3 *****
# *****************
layer {
  name: "ref_conv3_1"
  type: "Convolution"
  # bottom: "ref_conv2_2"
  bottom: "ref_conv2_2norm"
  # bottom: "ref_pool2"
  top: "ref_conv3_1"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
  weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "ref_relu3_1"
  type: "ReLU"
  bottom: "ref_conv3_1"
  top: "ref_conv3_1"
}
layer {
  name: "ref_conv3_2"
  type: "Convolution"
  bottom: "ref_conv3_1"
  top: "ref_conv3_2"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "ref_relu3_2"
  type: "ReLU"
  bottom: "ref_conv3_2"
  top: "ref_conv3_2"
}
layer {
  name: "ref_conv3_3"
  type: "Convolution"
  bottom: "ref_conv3_2"
  top: "ref_conv3_3"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
  weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ref_relu3_3"
  type: "ReLU"
  bottom: "ref_conv3_3"
  top: "ref_conv3_3"
}
layer {
  name: "ref_conv3_3norm"
  type: "BatchNorm"
  bottom: "ref_conv3_3"
  top: "ref_conv3_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

#---------------------------------------------------#

layer {
  name: "concat-conv3"
  bottom: "ref_conv3_3norm"
  bottom: "conv3_3norm"
  top: "concat_conv3_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

#---------------------------------------------------#

# *****************
# ***** conv4 *****
# *****************
layer {
  name: "conv4_1"
  type: "Convolution"
  # bottom: "conv3_3"
  bottom: "concat_conv3_3norm"
  # bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_3norm"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv4 *****
# *****************
layer {
  name: "ref_conv4_1"
  type: "Convolution"
  # bottom: "ref_conv3_3"
  bottom: "ref_conv3_3norm"
  # bottom: "ref_pool3"
  top: "ref_conv4_1"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
  weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu4_1"
  type: "ReLU"
  bottom: "ref_conv4_1"
  top: "ref_conv4_1"
}
layer {
  name: "ref_conv4_2"
  type: "Convolution"
  bottom: "ref_conv4_1"
  top: "ref_conv4_2"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
  weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu4_2"
  type: "ReLU"
  bottom: "ref_conv4_2"
  top: "ref_conv4_2"
}
layer {
  name: "ref_conv4_3"
  type: "Convolution"
  bottom: "ref_conv4_2"
  top: "ref_conv4_3"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu4_3"
  type: "ReLU"
  bottom: "ref_conv4_3"
  top: "ref_conv4_3"
}
layer {
  name: "ref_conv4_3norm"
  type: "BatchNorm"
  bottom: "ref_conv4_3"
  top: "ref_conv4_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

#---------------------------------------------------#

layer {
  name: "concat-conv4"
  bottom: "ref_conv4_3norm"
  bottom: "conv4_3norm"
  top: "concat_conv4_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
#---------------------------------------------------#
# *****************
# ***** conv5 *****
# *****************
layer {
  name: "conv5_1"
  type: "Convolution"
  # bottom: "conv4_3"
  bottom: "concat_conv4_3norm"
  # bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_3norm"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv5 *****
# *****************
layer {
  name: "ref_conv5_1"
  type: "Convolution"
  # bottom: "ref_conv4_3"
  bottom: "ref_conv4_3norm"
  # bottom: "ref_pool4"
  top: "ref_conv5_1"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
}
layer {
  name: "ref_relu5_1"
  type: "ReLU"
  bottom: "ref_conv5_1"
  top: "ref_conv5_1"
}
layer {
  name: "ref_conv5_2"
  type: "Convolution"
  bottom: "ref_conv5_1"
  top: "ref_conv5_2"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
}
layer {
  name: "ref_relu5_2"
  type: "ReLU"
  bottom: "ref_conv5_2"
  top: "ref_conv5_2"
}
layer {
  name: "ref_conv5_3"
  type: "Convolution"
  bottom: "ref_conv5_2"
  top: "ref_conv5_3"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
}
layer {
  name: "ref_relu5_3"
  type: "ReLU"
  bottom: "ref_conv5_3"
  top: "ref_conv5_3"
}
layer {
  name: "ref_conv5_3norm"
  type: "BatchNorm"
  bottom: "ref_conv5_3"
  top: "ref_conv5_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

#---------------------------------------------------#

layer {
  name: "concat-conv5"
  bottom: "ref_conv5_3norm"
  bottom: "conv5_3norm"
  top: "concat_conv5_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

#---------------------------------------------------#
# *****************
# ***** conv6 *****
# *****************
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "concat_conv5_3norm"
  top: "conv6_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
}
layer {
  name: "relu6_1"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
}
layer {
  name: "relu6_2"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
}
layer {
  name: "relu6_3"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
}
layer {
  name: "conv6_3norm"
  type: "BatchNorm"
  bottom: "conv6_3"
  top: "conv6_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv6 *****
# *****************
layer {
  name: "ref_conv6_1"
  type: "Convolution"
  bottom: "ref_conv5_3norm"
  top: "ref_conv6_1"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
}
layer {
  name: "ref_relu6_1"
  type: "ReLU"
  bottom: "ref_conv6_1"
  top: "ref_conv6_1"
}
layer {
  name: "ref_conv6_2"
  type: "Convolution"
  bottom: "ref_conv6_1"
  top: "ref_conv6_2"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
}
layer {
  name: "ref_relu6_2"
  type: "ReLU"
  bottom: "ref_conv6_2"
  top: "ref_conv6_2"
}
layer {
  name: "ref_conv6_3"
  type: "Convolution"
  bottom: "ref_conv6_2"
  top: "ref_conv6_3"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
}
layer {
  name: "ref_relu6_3"
  type: "ReLU"
  bottom: "ref_conv6_3"
  top: "ref_conv6_3"
}
layer {
  name: "ref_conv6_3norm"
  type: "BatchNorm"
  bottom: "ref_conv6_3"
  top: "ref_conv6_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

#---------------------------------------------------#

layer {
  name: "concat-conv6"
  bottom: "ref_conv6_3norm"
  bottom: "conv6_3norm"
  top: "concat_conv6_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

#---------------------------------------------------#
# *****************
# ***** conv7 *****
# *****************
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "concat_conv6_3norm"
  top: "conv7_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu7_1"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu7_2"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv7_3"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu7_3"
  type: "ReLU"
  bottom: "conv7_3"
  top: "conv7_3"
}

layer {
  name: "conv7_3norm"
  type: "BatchNorm"
  bottom: "conv7_3"
  top: "conv7_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
# *****************
# ***** conv7 *****
# *****************
layer {
  name: "ref_conv7_1"
  type: "Convolution"
  bottom: "ref_conv6_3norm"
  top: "ref_conv7_1"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu7_1"
  type: "ReLU"
  bottom: "ref_conv7_1"
  top: "ref_conv7_1"
}
layer {
  name: "ref_conv7_2"
  type: "Convolution"
  bottom: "ref_conv7_1"
  top: "ref_conv7_2"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
  weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu7_2"
  type: "ReLU"
  bottom: "ref_conv7_2"
  top: "ref_conv7_2"
}
layer {
  name: "ref_conv7_3"
  type: "Convolution"
  bottom: "ref_conv7_2"
  top: "ref_conv7_3"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu7_3"
  type: "ReLU"
  bottom: "ref_conv7_3"
  top: "ref_conv7_3"
}
layer {
  name: "ref_conv7_3norm"
  type: "BatchNorm"
  bottom: "ref_conv7_3"
  top: "ref_conv7_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}
#---------------------------------------------------#

layer {
  name: "concat-conv7"
  bottom: "ref_conv7_3norm"
  bottom: "conv7_3norm"
  top: "concat_conv7_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

#---------------------------------------------------#
# *****************
# ***** conv8 *****
# *****************
layer {
  name: "conv8_1"
  type: "Deconvolution"
  bottom: "concat_conv7_3norm"
  top: "conv8_1"
  convolution_param {
    num_output: 256
    kernel_size: 4
    pad: 1
    dilation: 1
    stride: 2
  }
}
layer {
  name: "relu8_1"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  # name: "conv8_2_"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu8_2"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv8_3"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_3"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu8_3"
  type: "ReLU"
  bottom: "conv8_3"
  top: "conv8_3"
}

# *****************
# ***** conv8 *****
# *****************
layer {
  name: "ref_conv8_1"
  type: "Deconvolution"
  bottom: "ref_conv7_3norm"
  top: "ref_conv8_1"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 256
    kernel_size: 4
    pad: 1
    dilation: 1
    stride: 2
  }
}
layer {
  name: "ref_relu8_1"
  type: "ReLU"
  bottom: "ref_conv8_1"
  top: "ref_conv8_1"
}
layer {
  name: "ref_conv8_2"
  # name: "ref_conv8_2_"
  type: "Convolution"
  bottom: "ref_conv8_1"
  top: "ref_conv8_2"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 256
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu8_2"
  type: "ReLU"
  bottom: "ref_conv8_2"
  top: "ref_conv8_2"
}
layer {
  name: "ref_conv8_3"
  type: "Convolution"
  bottom: "ref_conv8_2"
  top: "ref_conv8_3"
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
  convolution_param {
    weight_filler {
      type: "gaussian" # initialize the filters from a Gaussian
      std: 0.01        # distribution with stdev 0.01 (default mean: 0)
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
  num_output: 256
    kernel_size: 3
    pad: 1
    dilation: 1
  }
}
layer {
  name: "ref_relu8_3"
  type: "ReLU"
  bottom: "ref_conv8_3"
  top: "ref_conv8_3"
}

#---------------------------------------------------#

layer {
  name: "concat-conv8"
  bottom: "ref_conv8_3"
  bottom: "conv8_3"
  top: "concat_conv8_3"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

#---------------------------------------------------#

# *******************
# ***** Softmax *****
# *******************
layer {
  name: "conv8_313"
  type: "Convolution"
  bottom: "concat_conv8_3"
  top: "conv8_313"
  convolution_param {
    num_output: 313
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv8_313_rh"
  type: "Scale"
  bottom: "conv8_313"
  top: "conv8_313_rh"
  scale_param {
    bias_term: false
    filler {      type: 'constant'      value: 2.606    }
  }
}
layer {
  name: "class8_313_rh"
  type: "Softmax"
  bottom: "conv8_313_rh"
  top: "class8_313_rh"
}
# ********************
# ***** Decoding *****
# ********************
layer {
  name: "class8_ab"
  type: "Convolution"
  bottom: "class8_313_rh"
  top: "class8_ab"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "Silence"
  type: "Silence"
  bottom: "class8_ab"
}