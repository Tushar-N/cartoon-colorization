name: "Colorization_v6"

#--------------------Data Layers----------------#
layer {
  name: "col_sketch_data"
  type: "Data"
  top: "col_sketch_data"
  include { phase: TRAIN }
  transform_param {
   mirror: true
   crop_size: 176
  }
  data_param {
    source: "/work/04340/tushar_n/cartoon-colorization/data/lmdb/train_frames_lmdb"
    batch_size: 40
    backend: LMDB
  }
}

layer {
  name: "col_sketch_data"
  type: "Data"
  top: "col_sketch_data"
  include { phase: TEST }
  transform_param {
   mirror: false
   crop_size: 256
  }
  data_param {
    source: "/work/04340/tushar_n/cartoon-colorization/data/lmdb/val_frames_lmdb"
    batch_size: 1
    backend: LMDB
  }
}


layer {
  name: "bw_sketch_data"
  type: "Data"
  top: "bw_sketch_data"
  include { phase: TRAIN }
  transform_param {
   mirror: true
   crop_size: 176
  }
  data_param {
    source: "/work/04340/tushar_n/cartoon-colorization/data/lmdb/train_sketch_lmdb"
    batch_size: 40
    backend: LMDB
  }
}

layer {
  name: "bw_sketch_data"
  type: "Data"
  top: "bw_sketch_data"
  include { phase: TEST }
  transform_param {
   mirror: false
   crop_size: 256
  }
  data_param {
    source: "/work/04340/tushar_n/cartoon-colorization/data/lmdb/val_sketch_lmdb"
    batch_size: 1
    backend: LMDB
  }
}

layer {
  name: "col_reference_data"
  type: "Data"
  top: "col_reference_data"
  include { phase: TRAIN }
  transform_param {
   mirror: true
   crop_size: 176
  }
  data_param {
    source: "/work/04340/tushar_n/cartoon-colorization/data/lmdb/train_frames_lmdb"
    batch_size: 40
    backend: LMDB
  }
}

layer {
  name: "col_reference_data"
  type: "Data"
  top: "col_reference_data"
  include { phase: TEST }
  transform_param {
   mirror: false
   crop_size: 256
  }
  data_param {
    source: "/work/04340/tushar_n/cartoon-colorization/data/lmdb/val_frames_lmdb"
    batch_size: 1
    backend: LMDB
  }
}

#---------------------------------------------------#

# ****************************
# ***** Color Conversion *****
# ****************************
layer { # color conversion
  type: 'Python'
  name: 'img_lab'
  bottom: "col_sketch_data"
  top: "img_lab" # image in Lab space
  python_param {
    module: 'caffe_traininglayers'
    layer: 'BGR2LabLayer'
  }
}

layer {
  name: "img_slice"
  type: "Slice"
  bottom: "img_lab"
  top: "sketch_l" # [0,100]
  top: "data_ab" # [-110,110]
  propagate_down: false
  slice_param {
    axis: 1
    slice_point: 1
  }
}

# we don't care about sketch_l
layer {
  name: "silence_layer"
  type: "Silence"
  bottom: "sketch_l"
}


# take the bw sketch data and pretend it's the L channel
layer { # 0-center data_l channel
  name: "data_l_meansub"
  type: "Scale"
  bottom: "bw_sketch_data"
  top: "data_l" # [-50,50]
  propagate_down: false
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  scale_param {
    bias_term: True
    filler {      type: 'constant'      value: 1    }
    bias_filler {      type: 'constant'      value: -50    }
  }
}

# ****************************
# ***** PROCESS LABELS *******
# ****************************
layer { # subsample ab
  name: 'data_ab_ss'
  type: 'Convolution'
  bottom: "data_ab"
  top: "data_ab_ss" # subsampled colors
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 4
    group: 2
    weight_filler { type: 'constant' value: 1 }
  }
}
layer { # encode
  type: 'Python'
  name: 'ab_enc'
  bottom: "data_ab_ss"
  top: "gt_ab_313" # quantized gt colors
  python_param {
    module: 'caffe_traininglayers'
    layer: 'NNEncLayer'
  }
}
layer { # compute gray mask
  type: 'Python'
  name: 'nongray_mask'
  bottom: "data_ab_ss"
  top: "nongray_mask" # mask out grayscale images
  python_param {
    module: 'caffe_traininglayers'
    layer: 'NonGrayMaskLayer'
  }
}
layer { # compute prior boost
  type: 'Python'
  name: 'prior_boost'
  bottom: "gt_ab_313"
  top: "prior_boost" # gradient boosting factors
  python_param {
    module: 'caffe_traininglayers'
    layer: 'PriorBoostLayer'
  }
}
layer { # multiply nongray mask and prior boost
  type: 'Eltwise'
  name: 'prior_boost_nongray'
  bottom: "prior_boost"
  bottom: "nongray_mask"
  top: "prior_boost_nongray"
  eltwise_param {
    operation: 0
  }
}

# *****************
# **** S-conv1 ****
# *****************
layer {
  name: "bw_conv1_1"
  type: "Convolution"
  bottom: "data_l"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}

layer {
  name: "conv1_2norm"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** R-conv1 ****
# *****************
layer {
  name: "ref_bw_conv1_1"
  type: "Convolution"
  bottom: "col_reference_data"
  top: "ref_conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu1_1"
  type: "ReLU"
  bottom: "ref_conv1_1"
  top: "ref_conv1_1"
}
layer {
  name: "ref_conv1_2"
  type: "Convolution"
  bottom: "ref_conv1_1"
  top: "ref_conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu1_2"
  type: "ReLU"
  bottom: "ref_conv1_2"
  top: "ref_conv1_2"
}
layer {
  name: "ref_conv1_2norm"
  type: "BatchNorm"
  bottom: "ref_conv1_2"
  top: "ref_conv1_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}


# *****************
# **** S-conv2 ****
# *****************
layer {
  name: "conv2_1"
  type: "Convolution"
  # bottom: "conv1_2"
  bottom: "conv1_2norm"
  # bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2norm"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** R-conv2 ****
# *****************
layer {
  name: "ref_conv2_1"
  type: "Convolution"
  # bottom: "ref_conv1_2"
  bottom: "ref_conv1_2norm"
  # bottom: "ref_pool1"
  top: "ref_conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu2_1"
  type: "ReLU"
  bottom: "ref_conv2_1"
  top: "ref_conv2_1"
}
layer {
  name: "ref_conv2_2"
  type: "Convolution"
  bottom: "ref_conv2_1"
  top: "ref_conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu2_2"
  type: "ReLU"
  bottom: "ref_conv2_2"
  top: "ref_conv2_2"
}
layer {
  name: "ref_conv2_2norm"
  type: "BatchNorm"
  bottom: "ref_conv2_2"
  top: "ref_conv2_2norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** S-conv3 ****
# *****************
layer {
  name: "conv3_1"
  type: "Convolution"
  # bottom: "conv2_2"
  bottom: "conv2_2norm"
  # bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_3norm"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** R-conv3 ****
# *****************
layer {
  name: "ref_conv3_1"
  type: "Convolution"
  # bottom: "ref_conv2_2"
  bottom: "ref_conv2_2norm"
  # bottom: "ref_pool2"
  top: "ref_conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu3_1"
  type: "ReLU"
  bottom: "ref_conv3_1"
  top: "ref_conv3_1"
}
layer {
  name: "ref_conv3_2"
  type: "Convolution"
  bottom: "ref_conv3_1"
  top: "ref_conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu3_2"
  type: "ReLU"
  bottom: "ref_conv3_2"
  top: "ref_conv3_2"
}
layer {
  name: "ref_conv3_3"
  type: "Convolution"
  bottom: "ref_conv3_2"
  top: "ref_conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu3_3"
  type: "ReLU"
  bottom: "ref_conv3_3"
  top: "ref_conv3_3"
}
layer {
  name: "ref_conv3_3norm"
  type: "BatchNorm"
  bottom: "ref_conv3_3"
  top: "ref_conv3_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** S-conv4 ****
# *****************
layer {
  name: "conv4_1"
  type: "Convolution"
  # bottom: "conv3_3"
  bottom: "conv3_3norm"
  # bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_3norm"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** R-conv4 ****
# *****************
layer {
  name: "ref_conv4_1"
  type: "Convolution"
  # bottom: "ref_conv3_3"
  bottom: "ref_conv3_3norm"
  # bottom: "ref_pool3"
  top: "ref_conv4_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu4_1"
  type: "ReLU"
  bottom: "ref_conv4_1"
  top: "ref_conv4_1"
}
layer {
  name: "ref_conv4_2"
  type: "Convolution"
  bottom: "ref_conv4_1"
  top: "ref_conv4_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu4_2"
  type: "ReLU"
  bottom: "ref_conv4_2"
  top: "ref_conv4_2"
}
layer {
  name: "ref_conv4_3"
  type: "Convolution"
  bottom: "ref_conv4_2"
  top: "ref_conv4_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    dilation: 1
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu4_3"
  type: "ReLU"
  bottom: "ref_conv4_3"
  top: "ref_conv4_3"
}
layer {
  name: "ref_conv4_3norm"
  type: "BatchNorm"
  bottom: "ref_conv4_3"
  top: "ref_conv4_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# ** cat - conv4 **
# *****************

layer {
  name: "concat"
  bottom: "conv4_3norm"
  bottom: "ref_conv4_3norm"
  top: "cat_conv4_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

# *****************
# **** S-conv5 ****
# *****************
layer {
  name: "sk_conv5_1"
  type: "Convolution"
  # bottom: "conv4_3"
  bottom: "cat_conv4_3norm"
  # bottom: "pool4"
  top: "sk_conv5_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu5_1"
  type: "ReLU"
  bottom: "sk_conv5_1"
  top: "sk_conv5_1"
}
layer {
  name: "sk_conv5_2"
  type: "Convolution"
  bottom: "sk_conv5_1"
  top: "sk_conv5_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu5_2"
  type: "ReLU"
  bottom: "sk_conv5_2"
  top: "sk_conv5_2"
}
layer {
  name: "sk_conv5_3"
  type: "Convolution"
  bottom: "sk_conv5_2"
  top: "sk_conv5_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu5_3"
  type: "ReLU"
  bottom: "sk_conv5_3"
  top: "sk_conv5_3"
}
layer {
  name: "sk_conv5_3norm"
  type: "BatchNorm"
  bottom: "sk_conv5_3"
  top: "sk_conv5_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** R-conv5 ****
# *****************
layer {
  name: "ref_conv5_1"
  type: "Convolution"
  # bottom: "ref_conv4_3"
  bottom: "ref_conv4_3norm"
  # bottom: "ref_pool4"
  top: "ref_conv5_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu5_1"
  type: "ReLU"
  bottom: "ref_conv5_1"
  top: "ref_conv5_1"
}
layer {
  name: "ref_conv5_2"
  type: "Convolution"
  bottom: "ref_conv5_1"
  top: "ref_conv5_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu5_2"
  type: "ReLU"
  bottom: "ref_conv5_2"
  top: "ref_conv5_2"
}
layer {
  name: "ref_conv5_3"
  type: "Convolution"
  bottom: "ref_conv5_2"
  top: "ref_conv5_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 2
    dilation: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu5_3"
  type: "ReLU"
  bottom: "ref_conv5_3"
  top: "ref_conv5_3"
}
layer {
  name: "ref_conv5_3norm"
  type: "BatchNorm"
  bottom: "ref_conv5_3"
  top: "ref_conv5_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}



# *****************
# ** cat - conv5 **
# *****************

layer {
  name: "concat"
  bottom: "sk_conv5_3norm"
  bottom: "ref_conv5_3norm"
  top: "cat_conv5_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

# *****************
# **** S-conv6 ****
# *****************
layer {
  name: "sk_conv6_1"
  type: "Convolution"
  bottom: "cat_conv5_3norm"
  top: "sk_conv6_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu6_1"
  type: "ReLU"
  bottom: "sk_conv6_1"
  top: "sk_conv6_1"
}
layer {
  name: "sk_conv6_2"
  type: "Convolution"
  bottom: "sk_conv6_1"
  top: "sk_conv6_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu6_2"
  type: "ReLU"
  bottom: "sk_conv6_2"
  top: "sk_conv6_2"
}
layer {
  name: "sk_conv6_3"
  type: "Convolution"
  bottom: "sk_conv6_2"
  top: "sk_conv6_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu6_3"
  type: "ReLU"
  bottom: "sk_conv6_3"
  top: "sk_conv6_3"
}
layer {
  name: "sk_conv6_3norm"
  type: "BatchNorm"
  bottom: "sk_conv6_3"
  top: "sk_conv6_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** R-conv6 ****
# *****************
layer {
  name: "ref_conv6_1"
  type: "Convolution"
  bottom: "ref_conv5_3norm"
  top: "ref_conv6_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu6_1"
  type: "ReLU"
  bottom: "ref_conv6_1"
  top: "ref_conv6_1"
}
layer {
  name: "ref_conv6_2"
  type: "Convolution"
  bottom: "ref_conv6_1"
  top: "ref_conv6_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu6_2"
  type: "ReLU"
  bottom: "ref_conv6_2"
  top: "ref_conv6_2"
}
layer {
  name: "ref_conv6_3"
  type: "Convolution"
  bottom: "ref_conv6_2"
  top: "ref_conv6_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    dilation: 2
  }
  param { lr_mult: 2 decay_mult: 1 }
  param { lr_mult: 4 decay_mult: 0 }
}
layer {
  name: "ref_relu6_3"
  type: "ReLU"
  bottom: "ref_conv6_3"
  top: "ref_conv6_3"
}
layer {
  name: "ref_conv6_3norm"
  type: "BatchNorm"
  bottom: "ref_conv6_3"
  top: "ref_conv6_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# ** cat - conv6 **
# *****************

layer {
  name: "concat"
  bottom: "sk_conv6_3norm"
  bottom: "ref_conv6_3norm"
  top: "cat_conv6_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

# *****************
# **** S-conv7 ****
# *****************
layer {
  name: "sk_conv7_1"
  type: "Convolution"
  bottom: "cat_conv6_3norm"
  top: "sk_conv7_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu7_1"
  type: "ReLU"
  bottom: "sk_conv7_1"
  top: "sk_conv7_1"
}
layer {
  name: "sk_conv7_2"
  type: "Convolution"
  bottom: "sk_conv7_1"
  top: "sk_conv7_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu7_2"
  type: "ReLU"
  bottom: "sk_conv7_2"
  top: "sk_conv7_2"
}
layer {
  name: "sk_conv7_3"
  type: "Convolution"
  bottom: "sk_conv7_2"
  top: "sk_conv7_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu7_3"
  type: "ReLU"
  bottom: "sk_conv7_3"
  top: "sk_conv7_3"
}

layer {
  name: "sk_conv7_3norm"
  type: "BatchNorm"
  bottom: "sk_conv7_3"
  top: "sk_conv7_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}

# *****************
# **** R-conv7 ****
# *****************
layer {
  name: "ref_conv7_1"
  type: "Convolution"
  bottom: "ref_conv6_3norm"
  top: "ref_conv7_1"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "ref_relu7_1"
  type: "ReLU"
  bottom: "ref_conv7_1"
  top: "ref_conv7_1"
}
layer {
  name: "ref_conv7_2"
  type: "Convolution"
  bottom: "ref_conv7_1"
  top: "ref_conv7_2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "ref_relu7_2"
  type: "ReLU"
  bottom: "ref_conv7_2"
  top: "ref_conv7_2"
}
layer {
  name: "ref_conv7_3"
  type: "Convolution"
  bottom: "ref_conv7_2"
  top: "ref_conv7_3"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "ref_relu7_3"
  type: "ReLU"
  bottom: "ref_conv7_3"
  top: "ref_conv7_3"
}
layer {
  name: "ref_conv7_3norm"
  type: "BatchNorm"
  bottom: "ref_conv7_3"
  top: "ref_conv7_3norm"
  batch_norm_param{ }
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
  param {lr_mult: 0 decay_mult: 0}
}


# *****************
# ** cat - conv7 **
# *****************

layer {
  name: "concat"
  bottom: "sk_conv7_3norm"
  bottom: "ref_conv7_3norm"
  top: "cat_conv7_3norm"
  type: "Concat"
  concat_param {
    axis: 1
  }
}

# *****************
# **** S-conv8 ****
# *****************
layer {
  name: "sk_conv8_1"
  type: "Deconvolution"
  bottom: "cat_conv7_3norm"
  top: "sk_conv8_1"
  convolution_param {
    num_output: 256
    kernel_size: 4
    pad: 1
    dilation: 1
    stride: 2
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu8_1"
  type: "ReLU"
  bottom: "sk_conv8_1"
  top: "sk_conv8_1"
}
layer {
  name: "sk_conv8_2"
  # name: "conv8_2_"
  type: "Convolution"
  bottom: "sk_conv8_1"
  top: "sk_conv8_2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu8_2"
  type: "ReLU"
  bottom: "sk_conv8_2"
  top: "sk_conv8_2"
}
layer {
  name: "sk_conv8_3"
  type: "Convolution"
  bottom: "sk_conv8_2"
  top: "sk_conv8_3"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    dilation: 1
	weight_filler { type: "gaussian" std: 0.01 }
	bias_filler { type: "constant" value: 0 }
  }
  param { lr_mult: 10 decay_mult: 1 }
  param { lr_mult: 20 decay_mult: 0 }
}
layer {
  name: "sk_relu8_3"
  type: "ReLU"
  bottom: "sk_conv8_3"
  top: "sk_conv8_3"
}

# ****************************
# ***** Unary prediction *****
# ****************************
layer {
  name: "conv8_313"
  type: "Convolution"
  bottom: "sk_conv8_3"
  top: "conv8_313"
  convolution_param {
    num_output: 313
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
# ***************************
# ***** Boosting priors *****
# ***************************
layer {
  name: "conv8_313_boost"
  type: "Python"
  bottom: "conv8_313"
  bottom: "prior_boost_nongray"
  top: "conv8_313_boost"
  python_param {
    module: 'caffe_traininglayers'
    layer: 'ClassRebalanceMultLayer'
  }
}
# ************************
# ***** Softmax loss *****
# ************************
layer {
  name: "loss8_313"
  type: "SoftmaxCrossEntropyLoss"
  bottom: "conv8_313_boost"
  bottom: "gt_ab_313"
  top: 'loss8_313'
  loss_weight: 1.0
}
